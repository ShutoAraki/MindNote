{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WMD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM2n56iuoc1bOVUfSXD+7IS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShutoAraki/MindNote/blob/master/WMD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4ICwCP5SCUk",
        "colab_type": "text"
      },
      "source": [
        "# **Section 1. Word Mover's Distance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDj_Rj2kMc0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "35bc5ba3-1bb7-4959-dc68-829098144994"
      },
      "source": [
        "'''\n",
        "Download the pretrained Google News model here:\n",
        "https://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/\n",
        "'''\n",
        "\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "path = 'gdrive/My Drive/Colab Notebooks/BoilerMake2020/'\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format(path+'GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
        "\n",
        "# Import and download stopwords from NLTK.\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import download\n",
        "download('stopwords')  # Download stopwords list.\n",
        "\n",
        "# Initialize logging.\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s')\n",
        "\n",
        "# Normalizing word2vec vectors.\n",
        "model.init_sims(replace=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LE3Ki7ULAfj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d06ef24c-1de4-462d-c7a9-f52fea304cd9"
      },
      "source": [
        "# Sentence input\n",
        "first_sentence = 'I love ice cream'\n",
        "second_sentence = 'I love frozen yogurt'\n",
        "\n",
        "# Sentence split\n",
        "first_sentence = first_sentence.lower().split()\n",
        "second_sentence = second_sentence.lower().split()\n",
        "\n",
        "# Remove stopwords.\n",
        "stop_words = stopwords.words('english')\n",
        "first_sentence = [w for w in first_sentence if w not in stop_words]\n",
        "second_sentence = [w for w in second_sentence if w not in stop_words]\n",
        "\n",
        "# Compute distance\n",
        "# distance = model.wmdistance(first_sentence, second_sentence)\n",
        "# print('Ordinary distance = %.4f' % distance)\n",
        "distance = model.wmdistance(first_sentence, second_sentence)  # Compute WMD as normal.\n",
        "print('Normalized distance = %.4f' % distance)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normalized distance = 0.7571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2BjwmZGSNG-",
        "colab_type": "text"
      },
      "source": [
        "# **Section 2. WmdSimilarity**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiCFw1JUSVnq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dae081a3-eaac-4f68-f623-9eeca402b355"
      },
      "source": [
        "# Pre-processing a document.\n",
        "\n",
        "from nltk import word_tokenize\n",
        "download('punkt')  # Download data for tokenizer.\n",
        "\n",
        "def preprocess(doc):\n",
        "    doc = doc.lower()  # Lower the text.\n",
        "    doc = word_tokenize(doc)  # Split into words.\n",
        "    doc = [w for w in doc if not w in stop_words]  # Remove stopwords.\n",
        "    doc = [w for w in doc if w.isalpha()]  # Remove numbers and punctuation.\n",
        "    return doc"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXSGzPL4Senp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68505390-a61e-4f57-ef95-3b00c5b7b504"
      },
      "source": [
        "'''\n",
        "https://markroxor.github.io/gensim/static/notebooks/WMD_tutorial.html#Part-2:-Similarity-queries-using-WmdSimilarity\n",
        "'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nhttps://markroxor.github.io/gensim/static/notebooks/WMD_tutorial.html#Part-2:-Similarity-queries-using-WmdSimilarity\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY2LtYmkU2xb",
        "colab_type": "text"
      },
      "source": [
        "# **Section 3. WTD Documentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYEE1jnbU7C1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6e5aa41c-b534-40c0-80c5-5ade2ea753e4"
      },
      "source": [
        "! pip install pyemd"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyemd in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pyemd) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF9Mcg38WMDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "documents = [\"Human machine interface for lab abc computer applications\",\n",
        "             \"A survey of user opinion of computer system response time\",\n",
        "             \"The EPS user interface management system\",\n",
        "             \"System and human system engineering testing of EPS\",\n",
        "             \"Relation of user perceived response time to error measurement\",\n",
        "             \"The generation of random binary unordered trees\",\n",
        "             \"The intersection graph of paths in trees\",\n",
        "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
        "             \"Graph minors A survey\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbstMY_yVy77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Some sentences to test.\n",
        "sentence_obama = 'Obama speaks to the media in Illinois'.lower().split()\n",
        "sentence_president = 'The president greets the press in Chicago'.lower().split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fwyHN4uV6LL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove their stopwords.\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "sentence_obama = [w for w in sentence_obama if w not in stopwords]\n",
        "sentence_president = [w for w in sentence_president if w not in stopwords]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBxhsPRVWB-1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "445bed00-904c-466f-fe13-ba51da820164"
      },
      "source": [
        "# Compute WMD.\n",
        "distance = model.wmdistance(sentence_obama, sentence_president)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wmdistance` (Method will be removed in 4.0.0, use self.wv.wmdistance() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}